#!/usr/bin/env python
# -*- coding: utf-8 -*-
import cv2
import numpy as np
import argparse
import glob
import os
from scipy.spatial.distance import cdist
from scipy.spatial import distance
import matplotlib.pyplot as plt
import time
# import functions
import pupil_detection_optimal as pupil_detection
import rough_estimation
import evaluation,evaluation_angle,evaluation_corrected
import calibration
from scipy.optimize import fmin

start = time.clock()    # start timer

filelist_left = []
filelist_right = []
imglist_left = []
imglist_right = []
cimglist_left = []
cimglist_right = []
pupilcenter_list_left = []
pupilcenter_list_right = []
corrected_coords_left = []
corrected_coords_right = []
corrected_coords_x = []
corrected_coords_y = []
# Mat_centers = np.zeros((5, 3), np.float32)      # Zeilen, Spalten

img_resolution_factor = 1.0
pixelpitch_monitor = 0.058      # cm/px
pixelpitch_sensor = 0.00015875  # cm/px
distance_eye_monitor = 200.0    # cm
distance_eyes = 6.4             # cm
monitor_res_x = 1920.0            # px
monitor_res_y = 1080.0            # px

# Maya Kamera data
focal_lenght = 3.8              # cm
sensor_width = 0.549092588388   # cm
sensor_width_px = 3840.0          # px
sensor_height = 0.308864580969  # cm
sensor_height_px = 2160.0         # px
sensor_diagonal = 0.63          # cm


# load left eye images
for root, dirs, imgfiles in os.walk(r'../data/tests/3D/calibration/left'):     # create filelist of source images  z100_f18    z4_f5.4545      z4_f14      z4_45grad  photometric/noise/left
    for imgfile in imgfiles:
        if imgfile.endswith('.png'):
            filelist_left.append(root+'/'+imgfile)

for imagefile in filelist_left:
    img = cv2.imread(imagefile, 0)
    imglist_left.append(img)
    cimg_left = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)

# load right eye images
for root, dirs, imgfiles in os.walk(r'../data/tests/3D/calibration/right'):     # create filelist_right of source images  z100_f18    z4_f5.4545      z4_f14      z4_45grad  photometric/noise/left
    for imgfile in imgfiles:
        if imgfile.endswith('.png'):
            filelist_right.append(root+'/'+imgfile)

for imagefile in filelist_right:
    img = cv2.imread(imagefile, 0)
    imglist_right.append(img)
    cimg_right = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
    cimglist_right.append(cimg_right)

number_imgs = len(imglist_left)

height, width = img.shape       # get image size
height /= img_resolution_factor
width /= img_resolution_factor

# detect pupil center in left eye images
count = 1
for left_img in imglist_left:

    ## --- pupil detection method ---

    # center = pupil_detection.darkest_pixel(left_img, img_resolution_factor)
    # center = pupil_detection.distance_transform(left_img, img_resolution_factor)
    center = pupil_detection.center_of_mass(left_img, img_resolution_factor)
    # center = pupil_detection.edge_ellipse_fit(left_img, img_resolution_factor)
    # center = pupil_detection.ransac_ellipse_fit(left_img, img_resolution_factor)
    # center = pupil_detection.starburst(left_img, img_resolution_factor)
    # center = pupil_detection.hough_ellipse(left_img, img_resolution_factor)


    if center is not None:
        # print 'processing left image:', count, '/ 25'
        count += 1
        pupilcenter_list_left.append(center)
        # print center
    else:
        print('No Pupils Detected!')

# rearrange pupil coordinates to camera image center origin
pupilcenter_imgcoords = np.ravel(pupilcenter_list_left).reshape(number_imgs, 2)
pupil_coords_img_x = np.reshape(pupilcenter_imgcoords[:, 0], (number_imgs, 1))
pupil_coords_img_y = np.subtract(np.reshape(pupilcenter_imgcoords[:, 1], (number_imgs, 1)), height) * (-1)    # flip y-coordinates
pupilcenter_coords = np.hstack((pupil_coords_img_x, pupil_coords_img_y))
pupil_centered_left = np.subtract(pupilcenter_coords[:,:], ((width / 2), (height / 2)))

# calibration
norm_factor_left, HomographyMat_left = calibration.calibrate('left', img_resolution_factor)

# --- radial distortion correction ---
for coord in pupil_centered_left:
    alpha_current = np.arctan(np.sqrt((coord[0] * norm_factor_left) ** 2 + (coord[1] * norm_factor_left) ** 2))# / 1000.0)
    if alpha_current == 0:      # avoid division by 0
        radial_correction_factor = 0
    else:
        radial_correction_factor = np.tan(alpha_current) / np.sin(alpha_current)
    corrected_coords_left.append(coord * radial_correction_factor) # 1.05124209
corrected_coordsmat_left = np.ravel(corrected_coords_left).reshape(number_imgs, 2)

sensor_coords_corr_left = np.ravel(np.float32(corrected_coordsmat_left)).reshape(-1, number_imgs, 2)

if HomographyMat_left is not None:
    transformed_points_left = cv2.perspectiveTransform(sensor_coords_corr_left, HomographyMat_left)
    # print transformed_points_left
else:
    print('No Homography Matrix created!')

# ----------------------------------------------------------------------------------------------------------------------
# detect pupil center in right eye images
count = 1
for right_img in imglist_right:

    ## --- pupil detection method ---

    # center = pupil_detection.darkest_pixel(right_img, img_resolution_factor)
    # center = pupil_detection.distance_transform(right_img, img_resolution_factor)
    center = pupil_detection.center_of_mass(right_img, img_resolution_factor)
    # center = pupil_detection.edge_ellipse_fit(right_img, img_resolution_factor)
    # center = pupil_detection.ransac_ellipse_fit(right_img, img_resolution_factor)
    # center = pupil_detection.starburst(right_img, img_resolution_factor)
    # center = pupil_detection.hough_ellipse(right_img, img_resolution_factor)


    if center is not None:
        # print 'processing right image:', count, '/ 25'
        count += 1
        pupilcenter_list_right.append(center)
        # print center
    else:
        print('No Pupils Detected!')

# rearrange pupil coordinates to camera image center origin
pupilcenter_imgcoords = np.ravel(pupilcenter_list_right).reshape(number_imgs, 2)
pupil_coords_img_x = np.reshape(pupilcenter_imgcoords[:, 0], (number_imgs, 1))
pupil_coords_img_y = np.subtract(np.reshape(pupilcenter_imgcoords[:, 1], (number_imgs, 1)), height) * (-1)    # flip y-coordinates
pupilcenter_coords = np.hstack((pupil_coords_img_x, pupil_coords_img_y))
pupil_centered_right = np.subtract(pupilcenter_coords[:, :], ((width / 2), (height / 2)))

# calibration
norm_factor_right, HomographyMat_right = calibration.calibrate('right', img_resolution_factor)

# --- radial distortion correction ---
for coord in pupil_centered_right:
    alpha_current = np.arctan(np.sqrt((coord[0] * norm_factor_right) ** 2 + (coord[1] * norm_factor_right) ** 2))# / 1000.0)
    if alpha_current == 0:      # avoid division by 0
        radial_correction_factor = 0
    else:
        radial_correction_factor = np.tan(alpha_current) / np.sin(alpha_current)
    corrected_coords_right.append(coord * radial_correction_factor) # 1.05124209
corrected_coordsmat_right = np.ravel(corrected_coords_right).reshape(number_imgs, 2)

sensor_coords_corr_right = np.ravel(np.float32(corrected_coordsmat_right)).reshape(-1, number_imgs, 2)

if HomographyMat_right is not None:
    transformed_points_right = cv2.perspectiveTransform(sensor_coords_corr_right, HomographyMat_right)
    # print transformed_points_right
else:
    print('No Homography Matrix created!')

# # -- plot --
# pupil_coords_x = np.ravel(pupil_centered_left[:, 0]).reshape(number_imgs, 1)
# pupil_coords_y = np.ravel(pupil_centered_left[:, 1]).reshape(number_imgs, 1)
#
# plt.figure(num=None, figsize=(16, 9), dpi=80, facecolor='w', edgecolor='k')
# plt.plot(pupil_coords_x, pupil_coords_y, 'ko')
# # plt.axis([-5, 5, -5, 5])
# plt.xlabel('x-Richtung')
# plt.ylabel('y-Richtung')
#
# for i in range(1,number_imgs+1):
#     plt.annotate(i, xy=(pupil_coords_x[i - 1], pupil_coords_y[i - 1]), xytext = (-0.2, 0.2), textcoords = 'offset points', ha = 'right', va = 'bottom', color='0.1')
#
# plt.show()


## calculate distance
# distance = evaluation.distance_calc(transformed_points_left)
transformed_points2_left = transformed_points_left[0]
pupil_error_left_x = np.ravel(transformed_points2_left[:, 0]).reshape(number_imgs, 1)
pupil_error_left_y = np.ravel(transformed_points2_left[:, 1]).reshape(number_imgs, 1)

transformed_points2_right = transformed_points_right[0]
pupil_error_right_x = np.ravel(transformed_points2_right[:, 0]).reshape(number_imgs, 1)
pupil_error_right_y = np.ravel(transformed_points2_right[:, 1]).reshape(number_imgs, 1)

# plot_x = pupil_error_x
# plot_y = pupil_error_y
# plot1_x = np.ravel(transformed_points2_left[:, 0]).reshape(number_imgs, 1)
# plot1_y = np.ravel(transformed_points2_left[:, 1]).reshape(number_imgs, 1)
# plot2_x = np.ravel(transformed_points2_right[:, 0]).reshape(number_imgs, 1)
# plot2_y = np.ravel(transformed_points2_right[:, 1]).reshape(number_imgs, 1)
# plt.figure(num=None, figsize=(6.5, 6), dpi=140, facecolor='w', edgecolor='k') #figsize=(7, 7),
# plt.grid(color='0.5')
# plt.axhline(0, color='k')
# plt.axvline(0, color='k')
#
# # plt.plot(plot_x,plot_y, 'kx')
# plt.plot(plot1_x, plot1_y, 'bx')
# plt.plot(plot2_x, plot2_y, 'rx')
# # plt.axis([-0.4, 0.4, -0.4, 0.4])
# plt.subplots_adjust(left=0.14, right=0.86)
# plt.xlabel('$\Delta x$ (Pixel)')
# plt.ylabel('$\Delta y$ (Pixel)')
#
# for i in range(1, number_imgs+1):
#     plt.annotate(i, xy=(plot1_x[i - 1], plot1_y[i - 1]), xytext = (-0.2, 0.2), textcoords = 'offset points', ha = 'right', va = 'bottom', color='0.4')
# # plt.savefig('foo.pdf', figsize=(7, 7), bbox_inches='tight')
# plt.show()

# initial guesses

optimized_args = calibration.calibrate_3D(HomographyMat_left, HomographyMat_right, norm_factor_left, norm_factor_right, img_resolution_factor)
# distance_eyes = optimized_args[0]
# distance_eye_monitor = optimized_args[1]
# calculate fixation depth
for i in range(number_imgs):
    # monitor centered coordinates in cm
    x_left_cm = (transformed_points2_left[i, 0] - monitor_res_x / 2) * pixelpitch_monitor
    x_right_cm = (transformed_points2_right[i, 0] - monitor_res_x / 2) * pixelpitch_monitor
    y_left_cm = (transformed_points2_left[i, 1] - monitor_res_y / 2) * pixelpitch_monitor
    y_right_cm = (transformed_points2_right[i, 1] - monitor_res_y / 2) * pixelpitch_monitor

    if x_left_cm - x_right_cm + distance_eyes > 0:
        z_3D = distance_eyes * distance_eye_monitor / (x_left_cm - x_right_cm + distance_eyes)

    else:
        z_3D = np.inf

    x_3D_left =     (z_3D * (x_left_cm + (distance_eyes / 2)) / distance_eye_monitor) - (distance_eyes / 2)
    x_3D_right =    (z_3D * (x_right_cm - (distance_eyes / 2)) / distance_eye_monitor) + (distance_eyes / 2)
    x_3D = (x_3D_left + x_3D_right) / 2
    x_3D_2 = z_3D * (x_left_cm + x_right_cm) / (2 * distance_eye_monitor)
    y_3D_left =     z_3D * y_left_cm / distance_eye_monitor
    y_3D_right =    z_3D * y_right_cm / distance_eye_monitor
    y_3D = (y_3D_left + y_3D_right) / 2

    print 'Image number:', i+1
    print 'Pixel Left Eye:\t\t', transformed_points2_left[i, 0], 'Px\t', transformed_points2_left[i, 1], 'Px'
    print 'Pixel Right Eye:\t', transformed_points2_right[i, 0], 'Px\t', transformed_points2_left[i, 1], 'Px'
    print 'x:', round(x_3D, 3), 'cm'
    print 'y:', round(y_3D, 3), 'cm'
    print 'z:', round(z_3D, 3), 'cm', '\n'


elapsed = (time.clock() - start)
# print 'elapsed time:', elapsed

cv2.waitKey(0)
cv2.destroyAllWindows()


