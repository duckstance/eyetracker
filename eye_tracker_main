#!/usr/bin/env python
# -*- coding: utf-8 -*-
import cv2
import numpy as np
import argparse
import glob
import os
from scipy.spatial.distance import cdist
from scipy.spatial import distance
import matplotlib.pyplot as plt

# import functions
import pupil_detection
import rough_estimation
import evaluation

filelist = []
imglist = []
cimglist = []
pupilcenter_list = []
corrected_coords = []
corrected_coords_x = []
corrected_coords_y = []
# Mat_centers = np.zeros((5, 3), np.float32)      # Zeilen, Spalten

pixelpitch_monitor = 0.0576510902161  # cm/px
pixelpitch_sensor = 0.000142992861559
distance_eye_monitor = 200.96330687589918072

# Maya Kamera data
focal_lenght = 3.8              # cm
sensor_width = 0.549092588388   # cm
sensor_width_px = 3840          # px
sensor_height = 0.308864580969  # cm
sensor_height_px = 2160         # px
sensor_diagonal = 0.63          # cm


# calib_points = np.float32([[240, 135], [1680, 135], [1680, 945], [240, 945], [960, 540]])   # for 5 points
calib_points = np.float32([[0, 0],     [480, 0],   [960, 0],   [1440, 0],   [1920, 0],        # for 25 points
                           [1920, 270],[1440, 270],[960, 270], [480, 270],  [0, 270],
                           [0, 540],   [480, 540], [960, 540], [1440, 540], [1920, 540],
                           [1920, 810],[1440, 810],[960, 810], [480, 810],  [0, 810],
                           [0, 1080],  [480, 1080],[960, 1080],[1440, 1080],[1920, 1080]])


## --- load eye images ---
for root, dirs, files in os.walk(r'../data/ortho_z25_f40_s024/left'):     # create filelist of source images
    for file in files:
        if file.endswith('.tif'):
            filelist.append(root+'/'+file)

for imagefile in filelist:                                  # load source images ans store in list
    img_load = cv2.imread(imagefile, 0)
    imglist.append(img_load)

    cimg = cv2.cvtColor(img_load, cv2.COLOR_GRAY2BGR)
    cimglist.append(cimg)

height, width = img_load.shape                              # get image size

for img in imglist:

    ## --- pupil detection method ---

    # center = pupil_detection.darkest_pixel(img)
    # center = pupil_detection.edge_ellipse_fit(img)
    center = pupil_detection.center_of_mass(img)
    # center = pupil_detection.distance_transform(img)
    # center = pupil_detection.hough_circle(img)
    # center = pupil_detection.hough_ellipse(img)
    # center = pupil_detection.starburst(img)

    if center is not None:
        pupilcenter_list.append(center)
    else:
        print('No Circles Detected!')

# center pupil coordinates to origin
pupilcenter_imgcoords = np.ravel(pupilcenter_list).reshape(25, 2)

pupil_coords_x = np.subtract(np.reshape(pupilcenter_imgcoords[:, 0],(25, 1)), width) * (-1)     # flip x-coordinates
pupil_coords_y = np.subtract(np.reshape(pupilcenter_imgcoords[:, 1],(25, 1)), height) * (-1)    # flip y-coordinates
pupilcenter_coords = np.hstack((pupil_coords_x, pupil_coords_y))    # standard XY-Coordinate System

pupil_centered = np.subtract(pupilcenter_coords[:,:], ((width / 2)+0.5, (height / 2)+0.5))  #pupil_coords = np.subtract(pupilcenter_matrix[:,:], center_coordinate)

## -- plot --
# pupil_coords_x = np.ravel(pupil_centered[:, 0]).reshape(25, 1)
# pupil_coords_y = np.ravel(pupil_centered[:, 1]).reshape(25, 1)
#
# plt.figure(num=None, figsize=(16, 9), dpi=80, facecolor='w', edgecolor='k')
# plt.plot(pupil_coords_x, pupil_coords_y, 'ko')
# # plt.axis([-5, 5, -5, 5])
# plt.xlabel('x-Richtung')
# plt.ylabel('y-Richtung')
#
# for i in range(1,26):
#     plt.annotate(i, xy=(pupil_coords_x[i - 1], pupil_coords_y[i - 1]), color='r')
#
# plt.show()

# calculate target coordinates
[sensor_coords_left, sensor_coords_right] = evaluation.calibpoint_evaluation(calib_points, pupil_centered)

## --- radial distortion correction ---

# alpha_corner = np.arctan(np.sqrt(np.square(960) + np.square(540)) / 3469.1451497)  #angle between monitor corner, monitor center and eye

norm_factor = 960 / np.absolute(sensor_coords_left[0,0])

for coord in pupil_centered:

    alpha_current = np.arctan(np.sqrt((coord[0] * norm_factor) ** 2 + (coord[1] * norm_factor) ** 2) / (distance_eye_monitor / pixelpitch_monitor))
    if alpha_current == 0:      # avoid division by 0
        factor = 0
    else:
        factor = np.tan(alpha_current) / np.sin(alpha_current)

    corrected_coords.append(np.ravel(coord * factor))

corrected_coords_matrix = np.matrix(corrected_coords)
centered_centerlist = np.add(corrected_coords_matrix[:,:], (width / 2,height / 2))


src_Points = np.float32(centered_centerlist)

H, mask = cv2.findHomography(src_Points, calib_points) #, cv2.RANSAC, 5.0) cv2.LMEDS)             # find perspective transformation Matrix H

pts = np.ravel(src_Points).reshape(-1, 25, 2)

if H is not None:
    dst_Array = cv2.perspectiveTransform(pts, H)
    # print dst_Array
else:
    print('No Homography Matrix created!')

# print calib_points, '\n', dst_Array
error = np.matrix(np.subtract(calib_points, dst_Array))            # difference between x,y coords of source points and calibrated points
dist = np.sqrt(np.square(error[:, 0]) + np.square(error[:, 1]))     # euclidian distance between calibration points and mapped points

## calculate distance
# distance = evaluation.distance_calc(dst_Array)

print 'distance', dist, '\n Max:', np.max(dist)

cv2.waitKey(0)
cv2.destroyAllWindows()
