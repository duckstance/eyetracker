#!/usr/bin/env python
# -*- coding: utf-8 -*-
import numpy as np
import cv2
import cv2.cv as cv
import time
import matplotlib.pyplot as plt
from skimage import measure, feature, io, color, draw
from skimage.draw import ellipse_perimeter
from skimage import io
# from skimage.viewer import ImageViewer
from skimage import measure
from skimage import data, color
from skimage.feature import canny
from skimage.transform import hough_ellipse
from skimage.transform import resize
import scipy
import cPickle as pickle
import random

import time
import numpy as np

import rough_estimation


def darkest_pixel(img, scalefactor):

    img_resized = cv2.resize(img, (0, 0), fx=(1 / scalefactor), fy=(1 / scalefactor))
    # img_blur = cv2.GaussianBlur(img, (501,501), 50)
    img_blur = cv2.blur(img_resized, (int(150/scalefactor),int(150/scalefactor)))   #ortho 400  angle 250

    # cv2.imshow('blurred',img_blur)

    #find position of darkest area
    index_y, index_x = np.where(img_blur == img_blur.min())

    #calculate center of multiple minimums

    cx = (np.amin(index_x) + np.amax(index_x)) / 2.0
    cy = (np.amin(index_y) + np.amax(index_y)) / 2.0
    # equ = cv2.equalizeHist(img_blur)
    # ret, thresh2 = cv2.threshold(img_blur, 30, 255, cv2.THRESH_BINARY_INV)
    # cv2.imshow('tresh',thresh2)

    return (cx+0.5) * scalefactor, (cy+0.5) * scalefactor


def distance_transform(img, scalefactor):

    # img = cv2.imread('C:/Users/Arno/PycharmProjects/eyeTracker/data/eye_new/right/20141209_Ortho_1Cam__0800.png', 0)
    # cimg = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)

    img_small = cv2.resize(img, (0, 0), fx=(1 / scalefactor), fy=(1 / scalefactor))
    ret, thresh = cv2.threshold(img_small, 30, 255, cv2.THRESH_BINARY_INV)

    dist_transform = cv2.distanceTransform(thresh, cv2.cv.CV_DIST_L2, 5)
    # equalized = cv2.normalize(dist_transform, alpha=0., beta=1., norm_type=cv2.NORM_MINMAX)

    # img_rez = cv2.resize(equalized, (0, 0), fx=(1 / 4.0), fy=(1 / 4.0))
    # cv2.imshow('Dist Transform', img_rez)
    # viewer = ImageViewer(equalized)
    # viewer.show()
    index_y, index_x = np.where(dist_transform == dist_transform.max())

    #calculate center of multiple minimums
    center_coords = np.float(np.amin(index_x) + np.amax(index_x)) / 2, np.float(np.amin(index_y) + np.amax(index_y)) / 2
    cx = center_coords[0]
    cy = center_coords[1]

    return (cx + 0.5) * scalefactor, (cy + 0.5) * scalefactor


def center_of_mass(img, scalefactor):

    # cimg = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
    # img_blur = cv2.blur(img, (50, 50))      #
    # img_gaussian = cv2.GaussianBlur(img, (11, 11), 0)

    img_resized = cv2.resize(img, (0, 0), fx=(1 / scalefactor), fy=(1 / scalefactor), interpolation = cv2.INTER_LINEAR)

    ret, thresh = cv2.threshold(img_resized, 30, 255, cv2.THRESH_BINARY_INV)
    # cv2.imshow('blurred', thresh)

    contours = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

    cnt = contours[0]

    # cv2.drawContours(cimg, cnt, -1, (0, 255, 0), 2)

    # cv2.imshow('tresh', thresh2)

    M = cv2.moments(cnt[0])

    cx = M['m10'] / M['m00']
    cy = M['m01'] / M['m00']

    # cv2.circle(cimg, (int(cx), int(cy)), 1, (0, 0, 255), 2)

    # ellipse = cv2.fitEllipse(ellipse_points)
    # cv2.ellipse(cimg, ellipse, (255, 0, 0), 2)


    return (cx + 0.5) * scalefactor, (cy + 0.5) * scalefactor


def edge_ellipse_fit(img, scalefactor):

    img_resized = cv2.resize(img, (0, 0), fx=(1 / scalefactor), fy=(1 / scalefactor))
    ret, thresh = cv2.threshold(img_resized, 30, 255, cv2.THRESH_BINARY_INV)
    edge = canny(thresh, sigma=2).astype(np.uint8)
    edge[edge > 0] = 255
    # img_resized = cv2.resize(canny, (0, 0), fx=(1 / scalefactor), fy=(1 / scalefactor))
    # cv2.imshow('canny', img_resized)
    # viewer = ImageViewer(edge)
    # viewer.show()
    index_y, index_x = np.where(edge == edge.max())
    ellipse_points = np.vstack((index_x, index_y)).T
    ellipse = cv2.fitEllipse(ellipse_points)
    # cv2.ellipse(cimg, ellipse, (255, 0, 0), 1)

    ellipse_center = ellipse[0]
    cx = ellipse_center[0]
    cy = ellipse_center[1]

    return (cx + 0.5) * scalefactor, (cy + 0.5) * scalefactor


def ransac_ellipse_fit(img, scalefactor):

    # img = cv2.imread('../data/maya/ortho_z4_f5_s024/left/left01.tif', 0)

    img_resized = cv2.resize(img, (0, 0), fx=(1 / scalefactor), fy=(1 / scalefactor), interpolation = cv2.INTER_LINEAR)

    height, width = img_resized.shape

    ret, thresh = cv2.threshold(img_resized, 30, 255, cv2.THRESH_BINARY_INV)

    contours = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    cnt = contours[0]

    Rect = cv2.boundingRect(cnt[0])
    corner_lt = int(Rect[0]-0.1*Rect[2]), int(Rect[1]-0.1*Rect[3])  # create left-top ROI corner with 10% margin

    # handle left-top boundary violation
    if corner_lt[0] < 0:
        corner_lt = 0, corner_lt[1]
    if corner_lt[1] < 0:
        corner_lt = corner_lt[0], 0

    corner_rb = (int(corner_lt[0] + Rect[2]*1.2), int(corner_lt[1] + Rect[3]*1.2))  # create right-bottom ROI corner with 10% margin

    # handle right-bottom boundary violation
    if corner_rb[0] > width:
        corner_rb = width, corner_rb[1]
    if corner_rb[1] > height:
        corner_rb = corner_rb[0], height

    # cv2.rectangle(img_resized, corner_lt, corner_rb, (255, 0, 0), 2)

    img_crop = img_resized[corner_lt[1]:corner_rb[1], corner_lt[0]:corner_rb[0]]

    img = color.rgb2gray(img_crop)
    ret, thresh = cv2.threshold(img, 30, 255, cv2.THRESH_BINARY_INV)
    # cv2.imshow('img', img)
    img = canny(thresh, sigma=2).astype(np.uint8)
    img[img > 0] = 255
    # img = cv2.Canny(img, 500, 1000)



    coords = np.column_stack(np.nonzero(img))

    coords_shuffled = random.shuffle(coords)
    # thinning coords
    thinning_factor = 4 / scalefactor
    thinned = []
    i = 0
    for coord in coords:    # keep only every thinning_factor-th point
        if i % int(thinning_factor) == 0:
            thinned.append(coord)
        i += 1
    thinned_coords = np.ravel(thinned).reshape(len(thinned), 2)

    model, inliers = measure.ransac(thinned_coords, measure.EllipseModel, min_samples=5, residual_threshold=1, max_trials=200)

    cx = (model.params[1] + corner_lt[0])
    cy = (model.params[0] + corner_lt[1])

    return (cx + 0.5) * scalefactor, (cy + 0.5) * scalefactor


def starburst(img, scalefactor):

    # declarations and initialisations

    # length of rays
    raylength = int(600 / scalefactor)

    # threshold for gradient detection trigger
    gradient_thresh = 1
    # angular steps between rays in degree
    angular_steps = 2

    tone_list = []
    point_coords = []

    # black_img = np.zeros((500, 500), np.uint8)             # create blank image

    # img = cv2.imread('../data/maya/ortho_z4_f5_s024/left/left01.tif', 0)

    # resize image
    img_resized = cv2.resize(img, (0, 0), fx=(1/scalefactor), fy=(1/scalefactor))

    # reduce noise with median blur filter
    img = cv2.medianBlur(img_resized, 3)

    # create color image copy
    cimg = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)

    # store image dimensions
    height, width = img.shape

    # detect rough pupil center for starburst starting point
    rough_center = rough_estimation.darkest_area(img)
    rough_center_x = rough_center[0]
    rough_center_y = rough_center[1]

    # if raylength exceeds image boundaries shorten length
    if raylength > (width - rough_center_x-1) or raylength > rough_center_x-1:
        if rough_center_x <= width - rough_center_x:
            raylength = rough_center_x-1
        else:
            raylength = width - rough_center_x-1

    if raylength > (height - rough_center_y) or raylength > rough_center_y:
        if rough_center_y <= height - rough_center_y:
            raylength = rough_center_y-1
        else:
            raylength = height - rough_center_y-1

    # start timer to measure runtime duration
    start = time.clock()

    # iterate lines from 0 to 45 degree with stepsize angular_steps. Lines with higher angle are created by mirroring
    for alpha in range(0, 46, angular_steps):

        # preallocate and then reset temporary line arrays
        line1 = np.zeros((raylength, 3), int)
        line2 = np.zeros((raylength, 3), int)
        line3 = np.zeros((raylength, 3), int)
        line4 = np.zeros((raylength, 3), int)
        line5 = np.zeros((raylength, 3), int)
        line6 = np.zeros((raylength, 3), int)
        line7 = np.zeros((raylength, 3), int)
        line8 = np.zeros((raylength, 3), int)

        for i in range(0, raylength):

            # 1. Quadrant
            y = np.int((np.tan(alpha * np.pi / 180) * -i) + rough_center_y)
            x = i + rough_center_x

            if 0 < y < height and 0 < x < width:
                line1[i, 0] = img[y, x]
                line1[i, 1] = x
                line1[i, 2] = y
                cimg[y, x] = 255

            x = np.int((np.tan(alpha * np.pi / 180) * i) + rough_center_x)
            y = -i + rough_center_y

            if 0 < y < height and 0 < x < width:
                line2[i, 0] = img[y, x]
                line2[i, 1] = x
                line2[i, 2] = y
                cimg[y, x] = 255


            # 2. Quadrant
            y = np.int((np.tan(alpha * np.pi / 180) * -i) + rough_center_y)
            x = -i + rough_center_x

            if 0 < y < height and 0 < x < width:
                line3[i, 0] = img[y, x]
                line3[i, 1] = x
                line3[i, 2] = y
                cimg[y, x] = 255

            x = np.int((np.tan(alpha * np.pi / 180) * -i) + rough_center_x)
            y = -i + rough_center_y

            if 0 < y < height and 0 < x < width:
                line4[i, 0] = img[y, x]
                line4[i, 1] = x
                line4[i, 2] = y
                cimg[y, x] = 255


            # 3. quadrant
            y = np.int((np.tan(-alpha * np.pi / 180) * -i) + rough_center_y)
            x = -i + rough_center_x

            if 0 < y < height and 0 < x < width:
                line5[i, 0] = img[y, x]
                line5[i, 1] = x
                line5[i, 2] = y
                cimg[y, x] = 255

            x = np.int((np.tan(-alpha * np.pi / 180) * i) + rough_center_x)
            y = i + rough_center_y

            if 0 < y < height and 0 < x < width:
                line6[i, 0] = img[y, x]
                line6[i, 1] = x
                line6[i, 2] = y
                cimg[y, x] = 255


            # 4. Quadrant
            y = np.int((np.tan(alpha * np.pi / 180) * i) + rough_center_y)
            x = i + rough_center_x

            if 0 < y < height and 0 < x < width:
                line7[i, 0] = img[y, x]
                line7[i, 1] = x
                line7[i, 2] = y
                cimg[y, x] = 255

            x = np.int((np.tan(alpha * np.pi / 180) * i) + rough_center_x)
            y = i + rough_center_y

            if 0 < y < height and 0 < x < width:
                line8[i, 0] = img[y, x]
                line8[i, 1] = x
                line8[i, 2] = y
                cimg[y, x] = 255


        tone_list.append(line1)
        tone_list.append(line2)
        tone_list.append(line3)
        tone_list.append(line4)
        tone_list.append(line5)
        tone_list.append(line6)
        tone_list.append(line7)
        tone_list.append(line8)


    for k in tone_list:

        gradient = np.absolute(np.gradient(k[:, 0]))
        # print k[:, 0], '\n', gradient
        # plt.plot(gradient)
        # plt.ylabel('some numbers')
        # plt.show()

        position = np.where(gradient == gradient.max())
        first_coord = position[0]
        # take center for multiple gradient maxima
        center_1 = ((np.amin(first_coord) + np.amax(first_coord)) / 2)

        edge_point = k[center_1]
        edge_coord_x = edge_point[1]
        edge_coord_y = edge_point[2]

        if 1 < edge_coord_x < width-1 and 1 < edge_coord_y < height-1 and gradient.max() > gradient_thresh:
            edge_temp = edge_coord_x, edge_coord_y
            point_coords.append(edge_temp)


        cimg[edge_coord_y, edge_coord_x] = (0, 0, 255)


    # fit ellipse
    if len(point_coords) != 0:
        ellipse_points = np.ravel(point_coords).reshape(len(point_coords), 2)
        model, inliers = measure.ransac(ellipse_points, measure.EllipseModel, min_samples=5, residual_threshold=2, max_trials=200)

        cx = model.params[0]
        cy = model.params[1]

    else:
        print('No Edge Points detected!')
        cx = 0
        cy = 0

    # cv2.imshow('black', cimg)
    # elapsed = (time.clock() - start)
    # print 'elapsed time:', elapsed

    return (cx + 0.5) * scalefactor, (cy + 0.5) * scalefactor


def hough_ellipse(img, scalefactor):

    from skimage.transform import hough_ellipse

    start = time.clock()

    img_resized = cv2.resize(img, (0, 0), fx=(1 / scalefactor), fy=(1 / scalefactor), interpolation = cv2.INTER_LINEAR)

    height, width = img_resized.shape

    ret, thresh = cv2.threshold(img_resized, 30, 255, cv2.THRESH_BINARY_INV)
    # cv2.imshow('blurred', thresh)

    contours = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    cnt = contours[0]

    # cv2.drawContours(cimg, cnt, -1, (0, 255, 0), 1)

    # cv2.imshow('tresh', cimg)

    Rect = cv2.boundingRect(cnt[0])
    corner_lt = int(Rect[0]-0.1*Rect[2]), int(Rect[1]-0.1*Rect[3])  # create left-top ROI corner with 10% margin

    # handle left-top boundary violation
    if corner_lt[0] < 0:
        corner_lt = 0, corner_lt[1]
    if corner_lt[1] < 0:
        corner_lt = corner_lt[0], 0

    corner_rb = (int(corner_lt[0] + Rect[2]*1.2), int(corner_lt[1] + Rect[3]*1.2))  # create right-bottom ROI corner with 10% margin

    # handle right-bottom boundary violation
    if corner_rb[0] > width:
        corner_rb = width, corner_rb[1]
    if corner_rb[1] > height:
        corner_rb = corner_rb[0], height

    # cv2.rectangle(img_resized, corner_lt, corner_rb, (255, 0, 0), 2)


    img_crop = img_resized[corner_lt[1]:corner_rb[1], corner_lt[0]:corner_rb[0]]
    # cv2.imshow('rect', img_crop)
    height_crop, width_crop = img_crop.shape
    if width_crop >= height_crop:
        larger_dim = width_crop
        smaller_dim = height_crop
    if width_crop < height_crop:
        smaller_dim = width_crop
        larger_dim = height_crop

    img = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)

    img_gray = color.rgb2gray(img)
    ret, thresh = cv2.threshold(img_crop, 30, 255, cv2.THRESH_BINARY_INV)
    edges = canny(thresh, sigma=2)

    # height, width = edges.shape
    #
    # for column in range(0, width):
    #     if column % int(2) == 0:
    #         edges[:, column] = False
    #
    # for row in range(0, height):
    #     if row % int(2) == 0:
    #         edges[row, :] = False
    # viewer = ImageViewer(edges)
    # viewer.show()

    # Perform a Hough Transform
    # The accuracy corresponds to the bin size of a major axis.
    # The value is chosen in order to get a single high accumulator.
    # The threshold eliminates low accumulators
    result = hough_ellipse(edges, accuracy=4, threshold=25, min_size=(smaller_dim*0.4), max_size=(larger_dim*0.5))   # result = hough_ellipse(edges, accuracy=20, threshold=250, min_size=100, max_size=120) min_size: Minimal major axis length. max: Maximal minor axis length.

    result.sort(order='accumulator')

    # Estimated parameters for the ellipse
    best = result[-1]
    yc = int(best[1])
    xc = int(best[2])
    a = int(best[3])
    b = int(best[4])
    orientation = best[5]

    elapsed = (time.clock() - start)
    print 'elapsed time:', elapsed

    cx = (best[2] + corner_lt[0])
    cy = (best[1] + corner_lt[1])

    return (cx + 0.5) * scalefactor, (cy + 0.5) * scalefactor
